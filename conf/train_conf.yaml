# conf/config.yaml

# The embedding_dim_map is used to derive embedding_dim based on embedding_method.
# You can override embedding_method from the command line:
#   python train.py embedding_method=hvg
#
# Or you can override any other parameter by specifying its full path, e.g.:
#   python train.py dataset.basename=my_awesome_dataset

model: #if huggingface repo is provided, this model will be loaded and fine-tuned directly

# Here are some defaults:
embedding_method: "geneformer" #This refers to the precomputed "embeddings" in .obsm of the anndata object accessible throgh the sharelink in the dataset

input_dim_map:
  hvg: 512
  pca: 50
  scvi_fm: 50
  geneformer: 512
  gs: 8000

gene_based_cell_sentence: true # If true, use list of gene names as a representation of the cell

# Cell sentence configuration
cs_length: 50 # Number of tokens/words to keep from cell sentences (truncate to first n elements)
cs_col: "cell_sentence_2" # Column name containing cell sentences to process

# Omics datasets - represent actual omics data that can be processed as text_only or with numeric embeddings
# - All omics datasets have enc.prepare_ds applied to them
# - If text_only=true: cell sentences are truncated (if cs_length set) and processed as text
# - If text_only=false: numeric embeddings are loaded and used alongside text processing
omics_datasets:
  - name: "cellxgene_pseudo_bulk_3_5k"
    type: "multiplets"
    caption: "natural_language_annotation"
    text_only: true # If true, process this dataset as text-only (cell sentences); if false, use numeric embeddings
#  - name: "geo_70k"
#    type: "multiplets"
#    caption: "natural_language_annotation"
#    text_only: false  # This dataset would use numeric embeddings (e.g., geneformer, pca, etc.)

# Bio datasets - biological background knowledge datasets (always processed as text-only)
# - These do NOT have enc.prepare_ds applied (different data format)
# - These do NOT get cell sentence truncation
# - Use keep_columns to specify which columns to retain from the raw dataset
bio_datasets:
  - id: "jo-mengr/descriptions_genes"
    name: "gene_description"
    type: "multiplets"
    keep_columns: ["anchor", "positive"] # Columns to keep from this dataset

#test_datasets:
#  - name: "jo-mengr/human_pancreas_norm_complexBatch_single_no_caption"
#    type: "single"
# Add more test datasets as needed

text_encoder:
  name: "NeuML/bioclinical-modernbert-base-embeddings" #"NeuML/pubmedbert-base-embeddings"
  freeze_text_encoder: True
  unfreeze_last_n_layers: 1

#loss: "MultipleNegativesRankingLoss"
#loss: "ContrastiveLoss"
#evaluator: "TripletEvaluator" # If not provided, the default evaluator is used

adapter: #each output of both models parts is passed through a separate adapter
  omics_input_dim: #this will be overwritten by the embedding_dim_map
  hidden_dim: null
  output_dim: null

joint_adapter: #if desired, the outputs of both models parts are passed through a joint adapter after the seperate adapters.
  hidden_dim: 0 # null or 0=skip joint adapter, >0=MLP with hidden layer
  unfreeze_epoch: 1 # Epoch at which to enable the joint adapter

trainer:
  unfreeze_epoch: 16 #will unfreeze the whole text encoder
  output_dir: "../../models/trained"
  num_train_epochs: 1
  per_device_train_batch_size: 128
  per_device_eval_batch_size: 128
  learning_rate: 5e-2
  warmup_ratio: 0.1
  fp16: false
  bf16: false
  eval_strategy: "steps"
  eval_steps: 100
  save_strategy: "steps"
  save_steps: 2000
  save_total_limit: 2
  logging_steps: 100
  logging_first_step: True
  dataloader_num_workers: 0
  max_grad_norm: 1.0
