# conf/config.yaml

# The embedding_dim_map is used to derive embedding_dim based on embedding_method.
# You can override embedding_method from the command line:
#   python train.py embedding_method=hvg
#
# Or you can override any other parameter by specifying its full path, e.g.:
#   python train.py dataset.basename=my_awesome_dataset

# Here are some defaults:
embedding_method: "geneformer" #This refers to the precomputed "embeddings" in .obsm of the anndata object accessible throgh the sharelink in the dataset

input_dim_map:
  hvg: 2000
  pca: 64
  scvi: 64
  geneformer: 512

dataset:
  basename: "geo_70k_cellxgene_35K"
  type: "pairs"
  test_datasets:
    - "jo-mengr/bowel_disease_single"

text_encoder:
  name: "pritamdeka/S-BioBert-snli-multinli-stsb"
  freeze_text_encoder: True
  unfreeze_last_n_layers: 0

loss: "ContrastiveLoss"

adapter:
  omics_input_dim: None #this will be overwritten by the embedding_dim_map
  hidden_dim: 512
  output_dim: 2048

trainer:
  unfreeze_epoch: 0.03
  output_dir: "../../models/trained"
  num_train_epochs: 10
  per_device_train_batch_size: 256
  per_device_eval_batch_size: 256
  learning_rate: 2e-5
  warmup_ratio: 0.1
  fp16: true
  bf16: false
  eval_strategy: "steps"
  eval_steps: 1000
  save_strategy: "steps"
  save_steps: 1000
  save_total_limit: 2
  logging_steps: 1000
  run_name: "mmcontext"

save_dir: "out"
# You could also define logging via Hydraâ€™s logging config if desired,
# but here we do not override the default Hydra logging setup.
