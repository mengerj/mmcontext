defaults:
  - datasets: dataset_list.yaml
  - models: model_list.yaml
  - _self_

run:
  seed: 42
  n_rows: 50_000 # rows per dataset split
  batch_size: 512
  num_workers: 0
  overwrite: false # if true, overwrite existing embeddings; if false, skip if files exist
  hf_cache_dir: /scratch/local/menger/cache/huggingface
  
  # Parallelization settings
  enable_parallel: true # Enable parallel processing of dataset/model combinations
  max_workers: 4 # Maximum number of parallel workers (null = auto-detect CPU count)
  task_timeout: 7200 # Maximum time (seconds) per dataset/model combination (2 hours default)

  # GPU settings
  use_threads_for_gpu: true # Use ThreadPoolExecutor instead of ProcessPoolExecutor for GPU (better memory sharing)
  # Set max_workers to 1-2 for GPU processing to avoid memory conflicts
  # For CPU processing, you can use higher values (e.g., 4-8)

output:

  adata_cache: /scratch/global/menger/data/from_nxtcloud
  root: /scratch/global/menger/out/embeddings
  format: parquet # csv | parquet

slurm:
  store_id: true # if true add SLURM_JOB_ID to metadata

hydra:
  run:
    dir: ${hydra:runtime.cwd}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
