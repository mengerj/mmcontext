defaults:
  - dataset_list.yaml
  - model_list.yaml

run:
  seed: 42
  n_rows: 50_000 # rows per dataset split
  batch_size: 32 # Larger batch for better GPU utilization
  num_workers: 0 # IMPORTANT: No DataLoader workers to avoid CUDA issues
  overwrite: false # if true, overwrite existing embeddings; if false, skip if files exist

  # No parallelization settings needed - always serial processing
  task_timeout: 7200 # Maximum time (seconds) per dataset/model combination (2 hours default)

output:
  adata_cache: ${hydra:runtime.cwd}/data/from_nxtcloud
  root: ${hydra:runtime.cwd}/out/embeddings
  format: parquet # csv | parquet

slurm:
  store_id: true # if true add SLURM_JOB_ID to metadata

hydra:
  run:
    dir: ${hydra:runtime.cwd}/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
