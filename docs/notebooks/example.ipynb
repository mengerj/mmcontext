{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: context aware learning of multiple modalities with mmcontext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents of Tutorial\n",
    "\n",
    "This tutorial demonstrates how to use the mmcontext package to preprocess single-cell data. We'll walk through the steps of:\n",
    "\n",
    "1. Loading the Dataset\n",
    "2. Generating Embeddings\n",
    "3. Normalizing Embeddings\n",
    "4. Aligning Embeddings\n",
    "5. Constructing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading the Dataset\n",
    "\n",
    "The input data has to be an {class}`anndata.AnnData` object. First, we'll load the example dataset provided in data/small_cellxgene.h5ad. It is derived from cellxgene and contains cells of various tissues and celltypes from different studys. The scvi embedding included is provided by cellxgene and contains embeddings computed with the scvi variational autoencoder trained on the cellxgene corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root - INFO - Loading the example dataset, which is taken from cellxgene...\n",
      "AnnData object with n_obs × n_vars = 5600 × 1000\n",
      "    obs: 'soma_joinid', 'donor_id', 'disease', 'sex', 'dataset_id', 'cell_type', 'assay', 'tissue', 'cell_type_ontology_term_id', 'assay_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'is_primary_data'\n",
      "    var: 'soma_joinid', 'feature_id', 'feature_name', 'feature_length', 'nnz', 'n_measured_obs'\n",
      "    obsm: 'metadata_tissue_assay_cell_type', 'scvi'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import anndata\n",
    "\n",
    "data_path = \"../../data/test_data/small_cellxgene_data.h5ad\"\n",
    "# Load the dataset\n",
    "adata = anndata.read_h5ad(data_path)\n",
    "\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate Embeddings\n",
    "\n",
    "We will generate context embeddings based on the categorical metadata fields cell_type and tissue using the {class}`mmcontext.pp.CategoryEmbedder` class.\n",
    "The method is based on creating an embedding of the individual categories of a cell with a text model. The `embeddings_file_path` points to a dictionary that contains embeddings for a range of cell types and tissues from the cellxgene corpus, thereby allowing the method to work without needing an API call. Only if some categories are not found in the dictionary the api will be used. If only a few are unknown, these will just be filled with a zero embedding. The `unkown_threshold` parameter controls how many new categories are needed to use the API. For that of course an API Key will be needed, which has to be set as an environmental variable \"OPENAI_API_KEY\". \n",
    "\n",
    "We will use the precomputed data embeddings stored in adata.obsm['scvi'] as our data embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmcontext.pp.context_embedder - INFO - Loaded embeddings from file.\n",
      "mmcontext.pp.context_embedder - INFO - Embeddings dictionary contains the following categories: dict_keys(['cell_type', 'tissue', 'assay']) with a total of 947 elements.\n",
      "mmcontext.pp.embedder - INFO - Using external data embeddings provided.\n",
      "mmcontext.pp.embedder - INFO - Creating context embeddings...\n",
      "mmcontext.pp.context_embedder - INFO - Embeddings for 'cell_type' stored in adata.obsm['cell_type_emb']\n",
      "mmcontext.pp.context_embedder - INFO - Embeddings for 'tissue' stored in adata.obsm['tissue_emb']\n",
      "mmcontext.pp.context_embedder - INFO - Combined context embeddings stored in adata.obsm['c_emb']\n",
      "Context Embeddings Shape: (5600, 1536)\n",
      "Data Embeddings Shape: (5600, 50)\n"
     ]
    }
   ],
   "source": [
    "# Import the CategoryEmbedder class\n",
    "from mmcontext.pp import CategoryEmbedder, Embedder\n",
    "\n",
    "# Specify the categories to embed\n",
    "categories = [\"cell_type\", \"tissue\"]\n",
    "\n",
    "# Initialize the CategoryEmbedder\n",
    "category_embedder = CategoryEmbedder(\n",
    "    metadata_categories=categories,\n",
    "    model=\"text-embedding-3-small\",\n",
    "    combination_method=\"average\",\n",
    "    embeddings_file_path=\"../../data/emb_dicts/category_embeddings_text-embedding-3-small_metadata_embeddings.pkl.gz\",\n",
    ")\n",
    "# Initialize the Embedder without embedders\n",
    "embedder = Embedder(context_embedder=category_embedder)\n",
    "\n",
    "# Create embeddings using external embeddings\n",
    "embedder.create_embeddings(adata, data_embeddings=adata.obsm[\"scvi\"])\n",
    "\n",
    "# Confirm the shape of the context embeddings\n",
    "print(\"Context Embeddings Shape:\", adata.obsm[\"c_emb\"].shape)\n",
    "print(\"Data Embeddings Shape:\", adata.obsm[\"d_emb\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normalize Embeddings \n",
    "\n",
    "Now that the embeddings are created and stored in the adata object we can apply normalization. We will use the {class}`mmcontext.pp.MinMaxNormalizer` here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmcontext.pp.embedding_normalizer - INFO - Normalizing embeddings using min-max normalization...\n",
      "Normalized Data Embeddings Shape: (5600, 50)\n",
      "Normalized Context Embeddings Shape: (5600, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Import the MinMaxNormalizer class\n",
    "from mmcontext.pp import MinMaxNormalizer\n",
    "\n",
    "# Initialize the MinMaxNormalizer\n",
    "normalizer = MinMaxNormalizer()\n",
    "\n",
    "# Normalize the embeddings\n",
    "normalizer.normalize(adata)\n",
    "\n",
    "# Confirm that normalized embeddings are stored\n",
    "print(\"Normalized Data Embeddings Shape:\", adata.obsm[\"d_emb_norm\"].shape)\n",
    "print(\"Normalized Context Embeddings Shape:\", adata.obsm[\"c_emb_norm\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Aligning Embeddings\n",
    "\n",
    "After normalization we will now use a {class}`mmcontext.pp.DimAligner` to make sure the dimensions of both data and context embeddings are equal, as this will be nescessary for the model. We will use the {class}`mmcontext.pp.PCAReducer` for this. If embeddings are larger than target latent dimension, they will be reduced via PCA. If there are smaller, padding with zeros will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned Data Embeddings Shape: (5600, 64)\n",
      "Aligned Context Embeddings Shape: (5600, 64)\n"
     ]
    }
   ],
   "source": [
    "# Import the PCAReducer class\n",
    "from mmcontext.pp import PCAReducer\n",
    "\n",
    "# Initialize the PCAReducer with the desired latent dimension\n",
    "latent_dim = 64\n",
    "aligner = PCAReducer(latent_dim=latent_dim)\n",
    "\n",
    "# Align the embeddings\n",
    "aligner.align(adata)\n",
    "\n",
    "# Confirm that aligned embeddings are stored\n",
    "print(\"Aligned Data Embeddings Shape:\", adata.obsm[\"d_emb_aligned\"].shape)\n",
    "print(\"Aligned Context Embeddings Shape:\", adata.obsm[\"c_emb_aligned\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Constructing the Dataset\n",
    "\n",
    "Finally, we will construct a dataset using the aligned embeddings, suitable for training models with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in dataset: 5600\n"
     ]
    }
   ],
   "source": [
    "# Import the DataSetConstructor class\n",
    "from mmcontext.pp import DataSetConstructor\n",
    "\n",
    "# Initialize the DataSetConstructor\n",
    "dataset_constructor = DataSetConstructor(sample_id_key=\"soma_joinid\")\n",
    "\n",
    "# Add the AnnData object to the dataset\n",
    "dataset_constructor.add_anndata(adata)\n",
    "\n",
    "# Construct the dataset\n",
    "dataset = dataset_constructor.construct_dataset()\n",
    "\n",
    "# Display information about the dataset\n",
    "print(\"Total samples in dataset:\", len(dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmcontext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
