{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bad375f",
   "metadata": {},
   "source": [
    "# MMContextEncoder — quick‑start & usage tour\n",
    "\n",
    "This notebook uses the **`OmicsCaptionSimulator`** to generate toy data and walks through three ways of running the `MMContextEncoder` inside the Sentence‑Transformers framework:\n",
    "\n",
    "1. **Text‑only** (no numeric data)\n",
    "2. **Pre‑computed numeric embeddings**  \n",
    "   2 a. feature‑level tokens  2 b. sample‑level tokens\n",
    "3. **Random‑initialised numeric embeddings** (baseline)\n",
    "\n",
    "> *Training* will be covered in a follow‑up notebook. Here we focus on end‑to‑end **`encode`** calls and what comes out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304bb06",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89bbcd8",
   "metadata": {},
   "source": [
    "## 0  Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578df5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengerj/repos/mmcontext/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "/Users/mengerj/repos/mmcontext/.venv/lib/python3.11/site-packages/trimap/__init__.py:3: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/Users/mengerj/repos/mmcontext/.venv/lib/python3.11/site-packages/pkg_resources/__init__.py:3142: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/Users/mengerj/repos/mmcontext/.venv/lib/python3.11/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\n",
      "/Users/mengerj/repos/mmcontext/.venv/lib/python3.11/site-packages/wordcloud/wordcloud.py:35: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/mengerj/repos/mmcontext/.venv/lib/python3.11/site-packages/wordcloud/stopwords' mode='r' encoding='UTF-8'>\n",
      "  STOPWORDS = set(map(str.strip, open(os.path.join(FILE, 'stopwords')).readlines()))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mmcontext.utils import setup_logging\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51b61ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 200/200 [00:00<00:00, 167504.15 examples/s]\n",
      "Filter: 100%|██████████| 200/200 [00:00<00:00, 153975.92 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'sample_idx'],\n",
       "    num_rows: 160\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from mmcontext.models.mmcontextencoder import MMContextEncoder\n",
    "from mmcontext.simulator import OmicsCaptionSimulator\n",
    "\n",
    "sim = OmicsCaptionSimulator(n_samples=100, n_genes=10).simulate()\n",
    "token_df = sim.get_dataframe()\n",
    "raw_ds = sim.get_hf_dataset()[\"train\"]\n",
    "raw_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757a19c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embeddings shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# The token dataframe has entries of the following dimensions:\n",
    "print(f\"Sample embeddings shape: {token_df['embedding'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc7f500",
   "metadata": {},
   "source": [
    "The HuggingFace dataset has the columns\n",
    "`sample_idx, 'sentence1', 'sentence2', label`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d28332a",
   "metadata": {},
   "source": [
    "## 1  MMContextEncoder as a **pure text** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d5fbe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 10:23:09,714 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input → ['sample_idx:S1', 'Neuron']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding → [[-9.99999166e-01  9.19028595e-02 -9.96874273e-01 -6.12561703e-01\n",
      "  -9.63874042e-01  4.67113942e-01 -8.47504914e-01 -9.84450459e-01\n",
      "   1.09639160e-01 -1.06203169e-01 -7.82011151e-01 -1.68492451e-01\n",
      "   5.84925874e-05  9.99998629e-01  1.00110903e-01 -9.75917816e-01\n",
      "   7.74460971e-01  1.05135463e-01 -8.92424941e-01  4.47784990e-01\n",
      "   8.49705040e-01 -1.46661596e-02  6.78773463e-01  1.48798982e-02\n",
      "  -9.99661326e-01 -2.09409930e-02 -9.99751985e-01  2.98347682e-01\n",
      "   9.98913705e-01 -4.92799431e-02 -1.47239253e-01 -9.91691053e-02\n",
      "  -9.98491526e-01 -7.11548686e-01  5.00017703e-01  9.99980211e-01\n",
      "  -9.95522738e-01  2.97337230e-02  9.65869248e-01 -9.97810125e-01\n",
      "   9.97708559e-01  9.47759271e-01 -9.99164104e-01  8.97138715e-01\n",
      "  -9.99734938e-01 -9.18340236e-02 -9.85926330e-01  9.99412119e-01\n",
      "   9.35510337e-01  9.99569476e-01  3.51746738e-01 -8.14474225e-01\n",
      "  -1.71417326e-01  5.83500862e-01  9.58849430e-01  9.96164680e-01\n",
      "  -9.34911549e-01 -8.49859059e-01  9.76384103e-01 -1.83745846e-01\n",
      "  -4.93508503e-02  9.48858917e-01 -8.41619730e-01  9.51203823e-01\n",
      "  -6.08249307e-01 -9.99996841e-01 -9.10872996e-01  9.04398859e-01\n",
      "   9.44563210e-01  9.87324536e-01  9.91304696e-01  2.57290542e-01\n",
      "  -9.90194976e-01  2.49921642e-02  7.09200263e-01 -9.77561653e-01\n",
      "  -7.08614409e-01  2.05249399e-01 -6.62399054e-01  4.93232571e-02\n",
      "  -1.02819046e-02  9.53844339e-02 -9.83761489e-01 -9.99722898e-01\n",
      "   9.99878049e-01 -9.97938216e-01 -1.35312766e-01 -8.24280381e-01\n",
      "  -3.27909291e-01  9.18897390e-01 -6.44428730e-01  9.05066669e-01\n",
      "  -7.45823205e-01  9.31947231e-01  9.49050009e-01  8.63876462e-01\n",
      "  -6.34091794e-01  9.92042005e-01 -9.99763191e-01 -5.75472593e-01\n",
      "  -9.81449008e-01  8.26457202e-01 -9.99730766e-01 -8.92506838e-01\n",
      "  -9.98516738e-01 -9.34169114e-01 -9.99071598e-01 -9.90625978e-01\n",
      "   5.55898726e-01 -4.93590474e-01  9.99043345e-01 -4.01223958e-01\n",
      "  -7.31074691e-01  9.97819245e-01 -9.99990463e-01 -6.65379986e-02\n",
      "  -8.99447501e-01  6.80339217e-01  2.15214297e-01 -9.97501433e-01\n",
      "   1.90338865e-01 -9.99981284e-01 -8.20371568e-01  9.73059177e-01\n",
      "  -9.99096572e-01  9.96644497e-01  8.40946496e-01  9.56022978e-01]\n",
      " [-9.99999285e-01  1.27787506e-02 -9.99193549e-01 -3.36630009e-02\n",
      "  -9.95178103e-01  3.53165835e-01 -6.18928432e-01 -9.75962102e-01\n",
      "   1.42429024e-01  1.79816354e-02 -3.10551375e-01 -2.73941420e-02\n",
      "  -1.51180744e-01  9.99999702e-01 -5.13956130e-01 -9.31864142e-01\n",
      "   4.62806910e-01 -5.17889671e-02 -9.21924055e-01 -2.42769510e-01\n",
      "   9.49428558e-01  1.11931182e-01  1.55545801e-01 -5.06187454e-02\n",
      "  -9.99535859e-01  3.52938916e-03 -9.99792933e-01  2.07256511e-01\n",
      "   9.59627032e-01  7.37493858e-02  5.89617575e-03  1.25908209e-02\n",
      "  -9.76921260e-01 -4.88781512e-01  7.39360154e-01  9.99656796e-01\n",
      "  -9.91018116e-01 -7.35500827e-02  9.88904536e-01 -9.96896982e-01\n",
      "   9.89416122e-01  9.41396296e-01 -9.98055100e-01  9.33845878e-01\n",
      "  -9.99866009e-01 -2.09749579e-01 -9.94275749e-01  9.95211065e-01\n",
      "   9.29187238e-01  9.98923242e-01  7.46740222e-01  2.66381770e-01\n",
      "   3.33893038e-02  5.14356554e-01  8.46479535e-01  9.96909440e-01\n",
      "  -9.25683320e-01 -9.83657241e-01  9.46589887e-01 -5.70815921e-01\n",
      "   4.28938717e-02  9.13712978e-01 -8.72449338e-01  9.66301203e-01\n",
      "  -9.77517545e-01 -9.99999464e-01 -7.31644809e-01  7.52440810e-01\n",
      "   7.80694604e-01  9.81499016e-01  9.95448470e-01  5.35481535e-02\n",
      "  -9.81465757e-01  1.17568694e-01  9.08411682e-01 -9.98204172e-01\n",
      "  -6.23772144e-01  2.49023452e-01 -8.21773052e-01  2.46787801e-01\n",
      "  -2.64325768e-01 -1.29426301e-01 -7.45163798e-01 -9.98714328e-01\n",
      "   9.99800384e-01 -9.93785083e-01 -7.15502977e-01 -9.70484972e-01\n",
      "  -7.73431420e-01  5.36008358e-01 -7.10783601e-01  9.94809628e-01\n",
      "  -6.40615225e-01  8.25276971e-01  5.89332461e-01  5.18358588e-01\n",
      "  -6.23944759e-01  8.98126245e-01 -9.99969661e-01 -5.27494192e-01\n",
      "  -9.88712847e-01  9.40473497e-01 -9.99826729e-01 -9.60546494e-01\n",
      "  -9.90789711e-01 -8.04141521e-01 -9.99782681e-01 -9.94389713e-01\n",
      "   6.53989792e-01  9.28323865e-01  9.99710083e-01 -3.96880686e-01\n",
      "  -8.66659939e-01  9.98299837e-01 -9.99996722e-01 -1.42671522e-02\n",
      "  -8.84054303e-01 -4.16522861e-01  1.15751758e-01 -9.99881387e-01\n",
      "   1.98499098e-01 -9.99990523e-01 -8.31706166e-01  6.68604195e-01\n",
      "  -9.99891281e-01  9.92815793e-01  7.93423295e-01  9.52372849e-01]] …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_enc = MMContextEncoder(text_encoder_name=\"prajjwal1/bert-tiny\")  # any HF model works\n",
    "st_text = SentenceTransformer(modules=[text_enc])\n",
    "\n",
    "example = [raw_ds[\"sentence1\"][0], raw_ds[\"sentence2\"][0]]\n",
    "print(\"input →\", example)\n",
    "print(\"embedding →\", st_text.encode(example)[:5], \"…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea798c",
   "metadata": {},
   "source": [
    "`sentence1` is **treated like ordinary words**, because we never registered numeric embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7a785",
   "metadata": {},
   "source": [
    "If you initialise with `output_token_embeddings=True` you can retrieve the per‑token vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b14276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 10:23:29,511 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_enc_tokens = MMContextEncoder(\"prajjwal1/bert-tiny\", output_token_embeddings=True)\n",
    "st_tokens = SentenceTransformer(modules=[text_enc_tokens])\n",
    "\n",
    "res = st_tokens.encode(example, output_value=\"token_embeddings\")\n",
    "print(len(res))  # a list with length of batch size (2)\n",
    "res[0].shape  # the first element is a tensor of shape (n_tokens, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafce232",
   "metadata": {},
   "source": [
    "## 2  Using **pre‑computed** numeric embeddings\n",
    "### 2 a  Feature‑level (gene) tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c1a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = OmicsCaptionSimulator(n_samples=2000, n_genes=20, use_gene_level=True).simulate()\n",
    "token_df = sim.get_dataframe()\n",
    "raw_ds = sim.get_hf_dataset()[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc7c0c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4000/4000 [00:00<00:00, 628854.75 examples/s]\n",
      "Filter: 100%|██████████| 4000/4000 [00:00<00:00, 650910.42 examples/s]\n",
      "2025-05-20 10:26:26,965 - mmcontext.models.omicsencoder - INFO - Loaded embedding matrix with shape (21, 16)\n",
      "2025-05-20 10:26:26,966 - mmcontext.models.mmcontextencoder - INFO - Registered 21 new numeric samples (total 21). ≈0.000 GiB added. (Assuming float32 precision.)\n",
      "Prefixing sentence1: 100%|██████████| 3200/3200 [00:00<00:00, 169943.18 examples/s]\n",
      "2025-05-20 10:26:27,038 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input → sample_idx:g10 g2 g11 g20 g15 g8 g19 g4 g5 g12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled Embedding shape: (64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 155.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding shape: torch.Size([10, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enc_feat = MMContextEncoder(\n",
    "    \"prajjwal1/bert-tiny\", adapter_hidden_dim=32, adapter_output_dim=64, output_token_embeddings=True\n",
    ")\n",
    "enc_feat.register_initial_embeddings(token_df, data_origin=\"geneformer\")\n",
    "\n",
    "# prefix the dataset so the processor knows which column is omics\n",
    "pref_ds = enc_feat.prepare_ds(raw_ds, cell_sentences_cols=\"sentence1\", caption_col=\"sentence2\")\n",
    "\n",
    "st_feat = SentenceTransformer(modules=[enc_feat])\n",
    "row = pref_ds[0]\n",
    "print(\"input →\", row[\"sentence_1\"])\n",
    "encoding = st_feat.encode(row[\"sentence_1\"], output_value=\"sentence_embedding\")\n",
    "print(\"Pooled Embedding shape:\", encoding.shape)\n",
    "token_encoding = st_feat.encode(row[\"sentence_1\"], output_value=\"token_embeddings\")\n",
    "print(\"Token Embedding shape:\", token_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0bbd90",
   "metadata": {},
   "source": [
    "### 2 b  Sample‑level tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "526d1959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4000/4000 [00:00<00:00, 623734.70 examples/s]\n",
      "Filter: 100%|██████████| 4000/4000 [00:00<00:00, 620344.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "sim = OmicsCaptionSimulator(n_samples=2000, n_genes=20).simulate()\n",
    "token_df = sim.get_dataframe()\n",
    "raw_ds = sim.get_hf_dataset()[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8078e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 10:27:30,090 - mmcontext.models.omicsencoder - INFO - Loaded embedding matrix with shape (2001, 32)\n",
      "2025-05-20 10:27:30,091 - mmcontext.models.mmcontextencoder - INFO - Registered 2001 new numeric samples (total 2001). ≈0.000 GiB added. (Assuming float32 precision.)\n",
      "Prefixing sentence1: 100%|██████████| 3200/3200 [00:00<00:00, 164734.86 examples/s]\n",
      "2025-05-20 10:27:30,169 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input → sample_idx:S1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled Embedding shape: (64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 190.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embedding shape: torch.Size([1, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enc_samp = MMContextEncoder(\n",
    "    \"prajjwal1/bert-tiny\", adapter_hidden_dim=32, adapter_output_dim=64, output_token_embeddings=True\n",
    ")\n",
    "enc_samp.register_initial_embeddings(token_df, data_origin=\"pca\")\n",
    "\n",
    "pref_ds2 = enc_samp.prepare_ds(raw_ds, cell_sentences_cols=\"sentence1\", caption_col=\"sentence2\")\n",
    "st_samp = SentenceTransformer(modules=[enc_samp])\n",
    "print(\"input →\", pref_ds2[0][\"sentence_1\"])\n",
    "encoding = st_samp.encode(pref_ds2[0][\"sentence_1\"])\n",
    "print(\"Pooled Embedding shape:\", encoding.shape)\n",
    "token_encoding = st_samp.encode(pref_ds2[0][\"sentence_1\"], output_value=\"token_embeddings\")\n",
    "print(\"Token Embedding shape:\", token_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c5c470",
   "metadata": {},
   "source": [
    "The numeric vectors from `sample_df` are returned **unmodified** by the omics branch and then projected by the adapter.\n",
    "\n",
    "> **Note**  Embedding weights are *not* saved with the model; only the adapter weights are. When you reload the model you must call `register_initial_embeddings` again with a compatible matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a61e8d",
   "metadata": {},
   "source": [
    "## 3  Random‑initialised embeddings (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20814694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 4000/4000 [00:00<00:00, 622369.55 examples/s]\n",
      "Filter: 100%|██████████| 4000/4000 [00:00<00:00, 662058.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "sim = OmicsCaptionSimulator(n_samples=2000, n_genes=20).simulate()\n",
    "token_df = sim.get_dataframe()\n",
    "raw_ds = sim.get_hf_dataset()[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afe1c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 10:28:25,078 - mmcontext.models.omicsencoder - INFO - Loaded embedding matrix with shape (2001, 64)\n",
      "2025-05-20 10:28:25,079 - mmcontext.models.mmcontextencoder - INFO - Registered 2001 new numeric samples (total 2001). ≈0.000 GiB added. (Assuming float32 precision.)\n",
      "Prefixing sentence1: 100%|██████████| 3200/3200 [00:00<00:00, 162676.32 examples/s]\n",
      "2025-05-20 10:28:25,159 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10948668  0.1453564   0.18222867  0.01778192  0.16418293  0.18799107\n",
      "  0.23551662  0.02295085  0.14415075  0.51319635 -0.21753936 -0.08540704\n",
      " -0.22772713  0.33696035  0.17125972 -0.06174558  0.05924015  0.06253229\n",
      " -0.255522    0.19456369 -0.30784404  0.12620766 -0.15672968 -0.182354\n",
      " -0.12227616 -0.615613    0.24411213 -0.30043757  0.12713297 -0.29219785\n",
      " -0.49842006 -0.00670506  0.1654552  -0.01335027  0.19999892 -0.02134908\n",
      "  0.08071972 -0.05063622 -0.576203   -0.07939567  0.27898422  0.22024229\n",
      " -0.01880814 -0.19075714  0.30060425  0.31629696 -0.08036962  0.25729987\n",
      " -0.32603797 -0.01327852 -0.14412963  0.11517966  0.0690413   0.03479644\n",
      "  0.18441519  0.03432512 -0.19326882 -0.07836887  0.11872623 -0.31066564\n",
      "  0.23714355 -0.1661951   0.10479903  0.06035277 -0.04181308  0.03456398\n",
      "  0.48263597  0.01516395  0.21020971  0.4676326  -0.29020986 -0.0757796\n",
      "  0.04970912 -0.18281977  0.23352966  0.01416691 -0.14536797 -0.37176612\n",
      "  0.10221446 -0.0665024   0.34153995  0.05214313  0.24494225 -0.26356262\n",
      "  0.7760992   0.16102451  0.2867024  -0.12859966 -0.04700188  0.01364765\n",
      "  0.25157696  0.10401561 -0.04177259 -0.12000059 -0.10330483 -0.08474082\n",
      "  0.0500322   0.55015993 -0.19931127 -0.28714147 -0.268594    0.0567776\n",
      " -0.35016823 -0.25292194  0.12946591  0.06840713  0.01402437 -0.03979969\n",
      " -0.33913735  0.1052749   0.19116333  0.23639606  0.0269594  -0.24509959\n",
      "  0.15516672 -0.15419303 -0.04456975 -0.22919963  0.17405863 -0.34359202\n",
      "  0.452377   -0.28317055  0.05223709  0.14480579 -0.10712251  0.22847389\n",
      "  0.09870028  0.0906117 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enc_rand = MMContextEncoder(\"prajjwal1/bert-tiny\", adapter_hidden_dim=32)\n",
    "enc_rand.random_initial_embeddings(list(token_df[\"token\"]))\n",
    "pref_ds3 = enc_rand.prepare_ds(raw_ds, cell_sentences_cols=\"sentence1\", caption_col=\"sentence2\")\n",
    "\n",
    "st_rand = SentenceTransformer(modules=[enc_rand])\n",
    "print(st_rand.encode(pref_ds3[0][\"sentence_1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7dfe9",
   "metadata": {},
   "source": [
    "Random vectors let you benchmark how much pre‑computed representations help compared with an uninformed baseline (same dimension, same adapters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f9ce4",
   "metadata": {},
   "source": [
    "## 4  What’s next?\n",
    "* **Training** → use `SentenceTransformerTrainer` with `pref_ds`. Give the model a pair dataset (`label` = 1/0) and a suitable loss, e.g. `CosineSimilarityLoss`.\n",
    "* **Saving / loading** → `st_rand.save(path)`   then   `SentenceTransformer(path)`. Numeric lookup tables are *not* stored—re‑register before inference.\n",
    "* **Hub upload** → after training, `.push_to_hub()` works like for every Sentence‑Transformers model.\n",
    "\n",
    "A dedicated training notebook will cover these steps in detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
