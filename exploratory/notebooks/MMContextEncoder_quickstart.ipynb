{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bad375f",
   "metadata": {},
   "source": [
    "# MMContextEncoder — quick‑start & usage tour\n",
    "\n",
    "This notebook uses the **`OmicsCaptionSimulator`** to generate toy data and walks through three ways of running the `MMContextEncoder` inside the Sentence‑Transformers framework:\n",
    "\n",
    "1. **Text‑only** (no numeric data)\n",
    "2. **Pre‑computed numeric embeddings**  \n",
    "   2 a. feature‑level tokens  2 b. sample‑level tokens\n",
    "3. **Random‑initialised numeric embeddings** (baseline)\n",
    "\n",
    "> *Training* will be covered in a follow‑up notebook. Here we focus on end‑to‑end **`encode`** calls and what comes out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304bb06",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89bbcd8",
   "metadata": {},
   "source": [
    "## 0  Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "578df5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mmcontext.utils import setup_logging\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d51b61ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 200/200 [00:00<00:00, 87838.83 examples/s]\n",
      "Filter: 100%|██████████| 200/200 [00:00<00:00, 87181.54 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sample_idx', 'cell_sentence_1', 'cell_sentence_2', 'captions', 'label'],\n",
       "    num_rows: 160\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from mmcontext.models.MMContextEncoder import MMContextEncoder\n",
    "from mmcontext.simulator import OmicsCaptionSimulator\n",
    "\n",
    "sim = OmicsCaptionSimulator(n_samples=100, n_genes=10).simulate()\n",
    "gene_df, sample_df = sim.get_dataframes()\n",
    "raw_ds = sim.get_hf_dataset()[\"train\"]\n",
    "raw_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e9c8d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1</td>\n",
       "      <td>[-1.0454764366149902, -0.9293965101242065, 2.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g2</td>\n",
       "      <td>[-1.2294284105300903, -0.9434616565704346, 1.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g3</td>\n",
       "      <td>[-1.030511498451233, -1.0347418785095215, 1.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g4</td>\n",
       "      <td>[0.2129260152578354, 0.042285092175006866, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g5</td>\n",
       "      <td>[-1.7854403257369995, 0.669002890586853, -1.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g6</td>\n",
       "      <td>[-0.46827974915504456, 1.2896097898483276, 0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g7</td>\n",
       "      <td>[0.09945357590913773, 1.1276657581329346, 0.65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g8</td>\n",
       "      <td>[-1.6976884603500366, 0.11778832972049713, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g9</td>\n",
       "      <td>[0.019002540037035942, 0.7835861444473267, 1.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g10</td>\n",
       "      <td>[-0.49436676502227783, -0.7283456921577454, 1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token                                          embedding\n",
       "0    g1  [-1.0454764366149902, -0.9293965101242065, 2.4...\n",
       "1    g2  [-1.2294284105300903, -0.9434616565704346, 1.7...\n",
       "2    g3  [-1.030511498451233, -1.0347418785095215, 1.81...\n",
       "3    g4  [0.2129260152578354, 0.042285092175006866, 0.5...\n",
       "4    g5  [-1.7854403257369995, 0.669002890586853, -1.51...\n",
       "5    g6  [-0.46827974915504456, 1.2896097898483276, 0.8...\n",
       "6    g7  [0.09945357590913773, 1.1276657581329346, 0.65...\n",
       "7    g8  [-1.6976884603500366, 0.11778832972049713, -0....\n",
       "8    g9  [0.019002540037035942, 0.7835861444473267, 1.7...\n",
       "9   g10  [-0.49436676502227783, -0.7283456921577454, 1...."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc9b0818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g8 g1 g3 g5 g9 g4 g10 g2 g7 g6',\n",
       " 'g8 g1 g3 g5 g9 g4 g10 g2 g7 g6',\n",
       " 'g1 g3 g7 g6 g2 g4 g5 g9 g10 g8',\n",
       " 'g1 g3 g7 g6 g2 g4 g5 g9 g10 g8',\n",
       " 'g7 g8 g10 g2 g6 g5 g9 g3 g1 g4',\n",
       " 'g7 g8 g10 g2 g6 g5 g9 g3 g1 g4',\n",
       " 'g4 g2 g6 g8 g3 g9 g10 g1 g5 g7',\n",
       " 'g4 g2 g6 g8 g3 g9 g10 g1 g5 g7',\n",
       " 'g4 g10 g9 g6 g8 g5 g7 g1 g3 g2',\n",
       " 'g4 g10 g9 g6 g8 g5 g7 g1 g3 g2',\n",
       " 'g6 g8 g4 g7 g5 g10 g1 g9 g3 g2',\n",
       " 'g6 g8 g4 g7 g5 g10 g1 g9 g3 g2',\n",
       " 'g5 g1 g9 g10 g7 g3 g4 g6 g2 g8',\n",
       " 'g5 g1 g9 g10 g7 g3 g4 g6 g2 g8',\n",
       " 'g7 g8 g3 g1 g5 g10 g9 g4 g6 g2',\n",
       " 'g7 g8 g3 g1 g5 g10 g9 g4 g6 g2',\n",
       " 'g4 g7 g6 g2 g8 g10 g1 g3 g9 g5',\n",
       " 'g4 g7 g6 g2 g8 g10 g1 g3 g9 g5',\n",
       " 'g2 g1 g6 g3 g5 g10 g9 g7 g8 g4',\n",
       " 'g2 g1 g6 g3 g5 g10 g9 g7 g8 g4',\n",
       " 'g2 g1 g6 g9 g4 g5 g10 g3 g7 g8',\n",
       " 'g2 g1 g6 g9 g4 g5 g10 g3 g7 g8',\n",
       " 'g2 g5 g10 g8 g7 g4 g9 g3 g6 g1',\n",
       " 'g2 g5 g10 g8 g7 g4 g9 g3 g6 g1',\n",
       " 'g1 g7 g3 g2 g8 g6 g10 g5 g4 g9',\n",
       " 'g1 g7 g3 g2 g8 g6 g10 g5 g4 g9',\n",
       " 'g7 g2 g10 g5 g6 g9 g8 g1 g3 g4',\n",
       " 'g7 g2 g10 g5 g6 g9 g8 g1 g3 g4',\n",
       " 'g1 g5 g9 g4 g8 g2 g6 g3 g10 g7',\n",
       " 'g1 g5 g9 g4 g8 g2 g6 g3 g10 g7',\n",
       " 'g2 g1 g8 g9 g6 g4 g3 g10 g5 g7',\n",
       " 'g2 g1 g8 g9 g6 g4 g3 g10 g5 g7',\n",
       " 'g9 g8 g1 g3 g7 g5 g10 g4 g6 g2',\n",
       " 'g9 g8 g1 g3 g7 g5 g10 g4 g6 g2',\n",
       " 'g10 g8 g4 g7 g2 g6 g1 g5 g9 g3',\n",
       " 'g10 g8 g4 g7 g2 g6 g1 g5 g9 g3',\n",
       " 'g5 g8 g7 g9 g2 g6 g10 g4 g3 g1',\n",
       " 'g5 g8 g7 g9 g2 g6 g10 g4 g3 g1',\n",
       " 'g10 g8 g7 g6 g9 g5 g2 g4 g3 g1',\n",
       " 'g10 g8 g7 g6 g9 g5 g2 g4 g3 g1',\n",
       " 'g1 g6 g7 g3 g4 g5 g2 g8 g10 g9',\n",
       " 'g1 g6 g7 g3 g4 g5 g2 g8 g10 g9',\n",
       " 'g4 g3 g7 g10 g8 g1 g9 g5 g2 g6',\n",
       " 'g4 g3 g7 g10 g8 g1 g9 g5 g2 g6',\n",
       " 'g3 g6 g2 g9 g10 g8 g1 g7 g4 g5',\n",
       " 'g3 g6 g2 g9 g10 g8 g1 g7 g4 g5',\n",
       " 'g9 g7 g2 g4 g1 g5 g3 g6 g10 g8',\n",
       " 'g9 g7 g2 g4 g1 g5 g3 g6 g10 g8',\n",
       " 'g9 g6 g10 g7 g3 g5 g1 g4 g2 g8',\n",
       " 'g9 g6 g10 g7 g3 g5 g1 g4 g2 g8',\n",
       " 'g10 g8 g2 g7 g4 g9 g6 g3 g1 g5',\n",
       " 'g10 g8 g2 g7 g4 g9 g6 g3 g1 g5',\n",
       " 'g4 g2 g8 g5 g6 g10 g3 g1 g7 g9',\n",
       " 'g4 g2 g8 g5 g6 g10 g3 g1 g7 g9',\n",
       " 'g10 g4 g2 g9 g1 g8 g5 g3 g7 g6',\n",
       " 'g10 g4 g2 g9 g1 g8 g5 g3 g7 g6',\n",
       " 'g7 g2 g8 g4 g9 g1 g3 g5 g10 g6',\n",
       " 'g7 g2 g8 g4 g9 g1 g3 g5 g10 g6',\n",
       " 'g8 g4 g6 g5 g9 g10 g3 g1 g7 g2',\n",
       " 'g8 g4 g6 g5 g9 g10 g3 g1 g7 g2',\n",
       " 'g5 g9 g4 g10 g3 g8 g1 g7 g6 g2',\n",
       " 'g5 g9 g4 g10 g3 g8 g1 g7 g6 g2',\n",
       " 'g8 g9 g7 g1 g10 g6 g5 g4 g3 g2',\n",
       " 'g8 g9 g7 g1 g10 g6 g5 g4 g3 g2',\n",
       " 'g8 g9 g1 g5 g3 g10 g7 g6 g2 g4',\n",
       " 'g8 g9 g1 g5 g3 g10 g7 g6 g2 g4',\n",
       " 'g1 g3 g7 g8 g6 g9 g5 g4 g2 g10',\n",
       " 'g1 g3 g7 g8 g6 g9 g5 g4 g2 g10',\n",
       " 'g5 g2 g3 g1 g6 g7 g10 g9 g4 g8',\n",
       " 'g5 g2 g3 g1 g6 g7 g10 g9 g4 g8',\n",
       " 'g7 g8 g1 g3 g2 g6 g4 g9 g10 g5',\n",
       " 'g7 g8 g1 g3 g2 g6 g4 g9 g10 g5',\n",
       " 'g7 g6 g10 g8 g9 g2 g5 g1 g4 g3',\n",
       " 'g7 g6 g10 g8 g9 g2 g5 g1 g4 g3',\n",
       " 'g3 g10 g6 g1 g8 g5 g4 g2 g7 g9',\n",
       " 'g3 g10 g6 g1 g8 g5 g4 g2 g7 g9',\n",
       " 'g8 g10 g6 g5 g9 g7 g4 g2 g3 g1',\n",
       " 'g8 g10 g6 g5 g9 g7 g4 g2 g3 g1',\n",
       " 'g6 g9 g4 g10 g8 g5 g2 g3 g7 g1',\n",
       " 'g6 g9 g4 g10 g8 g5 g2 g3 g7 g1',\n",
       " 'g2 g10 g5 g7 g1 g3 g6 g9 g8 g4',\n",
       " 'g2 g10 g5 g7 g1 g3 g6 g9 g8 g4',\n",
       " 'g5 g1 g3 g9 g7 g4 g6 g8 g10 g2',\n",
       " 'g5 g1 g3 g9 g7 g4 g6 g8 g10 g2',\n",
       " 'g9 g6 g7 g8 g10 g2 g3 g5 g1 g4',\n",
       " 'g9 g6 g7 g8 g10 g2 g3 g5 g1 g4',\n",
       " 'g7 g5 g8 g10 g2 g6 g9 g3 g1 g4',\n",
       " 'g7 g5 g8 g10 g2 g6 g9 g3 g1 g4',\n",
       " 'g9 g2 g10 g3 g5 g4 g6 g7 g8 g1',\n",
       " 'g9 g2 g10 g3 g5 g4 g6 g7 g8 g1',\n",
       " 'g8 g5 g7 g9 g2 g6 g10 g1 g3 g4',\n",
       " 'g8 g5 g7 g9 g2 g6 g10 g1 g3 g4',\n",
       " 'g3 g6 g9 g1 g7 g8 g10 g4 g5 g2',\n",
       " 'g3 g6 g9 g1 g7 g8 g10 g4 g5 g2',\n",
       " 'g1 g7 g5 g4 g9 g2 g6 g3 g8 g10',\n",
       " 'g1 g7 g5 g4 g9 g2 g6 g3 g8 g10',\n",
       " 'g4 g10 g8 g1 g6 g9 g3 g5 g7 g2',\n",
       " 'g4 g10 g8 g1 g6 g9 g3 g5 g7 g2',\n",
       " 'g10 g2 g3 g7 g1 g5 g8 g9 g4 g6',\n",
       " 'g10 g2 g3 g7 g1 g5 g8 g9 g4 g6',\n",
       " 'g9 g1 g10 g2 g6 g4 g7 g3 g5 g8',\n",
       " 'g9 g1 g10 g2 g6 g4 g7 g3 g5 g8',\n",
       " 'g9 g10 g7 g8 g3 g5 g2 g4 g1 g6',\n",
       " 'g9 g10 g7 g8 g3 g5 g2 g4 g1 g6',\n",
       " 'g7 g3 g8 g10 g2 g4 g5 g1 g6 g9',\n",
       " 'g7 g3 g8 g10 g2 g4 g5 g1 g6 g9',\n",
       " 'g5 g2 g6 g7 g1 g4 g3 g8 g9 g10',\n",
       " 'g5 g2 g6 g7 g1 g4 g3 g8 g9 g10',\n",
       " 'g7 g6 g3 g10 g1 g5 g2 g8 g4 g9',\n",
       " 'g7 g6 g3 g10 g1 g5 g2 g8 g4 g9',\n",
       " 'g4 g8 g6 g9 g10 g5 g2 g3 g7 g1',\n",
       " 'g4 g8 g6 g9 g10 g5 g2 g3 g7 g1',\n",
       " 'g5 g3 g1 g4 g2 g9 g8 g6 g7 g10',\n",
       " 'g5 g3 g1 g4 g2 g9 g8 g6 g7 g10',\n",
       " 'g2 g3 g7 g5 g1 g8 g6 g9 g10 g4',\n",
       " 'g2 g3 g7 g5 g1 g8 g6 g9 g10 g4',\n",
       " 'g10 g5 g7 g1 g9 g4 g6 g2 g3 g8',\n",
       " 'g10 g5 g7 g1 g9 g4 g6 g2 g3 g8',\n",
       " 'g3 g10 g1 g7 g4 g5 g8 g6 g2 g9',\n",
       " 'g3 g10 g1 g7 g4 g5 g8 g6 g2 g9',\n",
       " 'g4 g7 g2 g3 g10 g8 g9 g1 g6 g5',\n",
       " 'g4 g7 g2 g3 g10 g8 g9 g1 g6 g5',\n",
       " 'g7 g1 g4 g5 g3 g2 g8 g10 g6 g9',\n",
       " 'g7 g1 g4 g5 g3 g2 g8 g10 g6 g9',\n",
       " 'g6 g7 g5 g2 g8 g4 g3 g1 g9 g10',\n",
       " 'g6 g7 g5 g2 g8 g4 g3 g1 g9 g10',\n",
       " 'g10 g2 g8 g4 g7 g1 g9 g3 g6 g5',\n",
       " 'g10 g2 g8 g4 g7 g1 g9 g3 g6 g5',\n",
       " 'g2 g6 g4 g5 g9 g7 g10 g8 g1 g3',\n",
       " 'g2 g6 g4 g5 g9 g7 g10 g8 g1 g3',\n",
       " 'g1 g7 g5 g4 g9 g6 g3 g8 g2 g10',\n",
       " 'g1 g7 g5 g4 g9 g6 g3 g8 g2 g10',\n",
       " 'g4 g5 g10 g9 g2 g1 g7 g6 g3 g8',\n",
       " 'g4 g5 g10 g9 g2 g1 g7 g6 g3 g8',\n",
       " 'g7 g4 g2 g9 g8 g5 g10 g1 g3 g6',\n",
       " 'g7 g4 g2 g9 g8 g5 g10 g1 g3 g6',\n",
       " 'g5 g2 g8 g10 g7 g1 g9 g6 g3 g4',\n",
       " 'g5 g2 g8 g10 g7 g1 g9 g6 g3 g4',\n",
       " 'g7 g1 g5 g9 g8 g10 g4 g3 g6 g2',\n",
       " 'g7 g1 g5 g9 g8 g10 g4 g3 g6 g2',\n",
       " 'g10 g2 g9 g5 g4 g8 g1 g3 g7 g6',\n",
       " 'g10 g2 g9 g5 g4 g8 g1 g3 g7 g6',\n",
       " 'g6 g9 g10 g2 g1 g8 g4 g5 g7 g3',\n",
       " 'g6 g9 g10 g2 g1 g8 g4 g5 g7 g3',\n",
       " 'g2 g5 g9 g4 g6 g1 g8 g7 g10 g3',\n",
       " 'g2 g5 g9 g4 g6 g1 g8 g7 g10 g3',\n",
       " 'g10 g2 g6 g3 g5 g9 g7 g1 g4 g8',\n",
       " 'g10 g2 g6 g3 g5 g9 g7 g1 g4 g8',\n",
       " 'g2 g9 g8 g7 g1 g4 g5 g6 g10 g3',\n",
       " 'g2 g9 g8 g7 g1 g4 g5 g6 g10 g3',\n",
       " 'g8 g10 g9 g4 g7 g1 g6 g3 g5 g2',\n",
       " 'g8 g10 g9 g4 g7 g1 g6 g3 g5 g2',\n",
       " 'g10 g5 g8 g6 g9 g3 g2 g7 g4 g1',\n",
       " 'g10 g5 g8 g6 g9 g3 g2 g7 g4 g1',\n",
       " 'g3 g9 g5 g1 g7 g6 g8 g4 g2 g10',\n",
       " 'g3 g9 g5 g1 g7 g6 g8 g4 g2 g10',\n",
       " 'g10 g4 g8 g6 g1 g2 g7 g5 g3 g9',\n",
       " 'g10 g4 g8 g6 g1 g2 g7 g5 g3 g9',\n",
       " 'g7 g4 g1 g8 g10 g5 g2 g3 g9 g6',\n",
       " 'g7 g4 g1 g8 g10 g5 g2 g3 g9 g6']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ds[\"cell_sentence_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "757a19c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene embeddings shape: (10,)\n",
      "Sample embeddings shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# The gene and sample dataframes have entries of the following dimensions:\n",
    "print(f\"Gene embeddings shape: {gene_df['embedding'].shape}\")\n",
    "print(f\"Sample embeddings shape: {sample_df['embedding'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc7f500",
   "metadata": {},
   "source": [
    "The HuggingFace dataset has the columns\n",
    "`sample_idx, 'cell_sentence_1', 'cell_sentence_2', captions, label`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d28332a",
   "metadata": {},
   "source": [
    "## 1  MMContextEncoder as a **pure text** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5fbe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input → ['S1', 'This is a Neuron from skin with scRNA-seq']\n",
      "embedding → [[ 0.17870897 -0.18881485  0.1618496   0.2277055  -0.17832585  0.1028291\n",
      "  -0.29022208 -0.00083416 -0.12848191  0.48940802 -0.16683114  0.06225635\n",
      "  -0.00932869  0.33577704  0.10112365  0.2780464   0.22146592 -0.23232459\n",
      "   0.14874886 -0.57021034  0.33698675  0.31272697 -0.05247811 -0.143991\n",
      "   0.12462245  0.23459499  0.09060437 -0.13936508  0.4014689  -0.17929876\n",
      "   0.01188798  0.04319223 -0.14096665  0.01878069  0.15557246  0.3154393\n",
      "  -0.26579973 -0.20207444 -0.01926843 -0.02130661 -0.03827694 -0.16857629\n",
      "   0.13937666  0.05459056  0.06019242 -0.12200861  0.11641523 -0.07209309\n",
      "  -0.17957948 -0.08626628 -0.06949704 -0.16139907  0.04034781  0.1302222\n",
      "   0.1533053   0.06499399  0.02499971  0.02033132  0.12005767  0.1827635\n",
      "  -0.29521948 -0.03016078  0.2764179   0.12270568  0.25018543 -0.2104099\n",
      "  -0.21742357  0.1748561  -0.07294507  0.19347528  0.26182407  0.28095782\n",
      "   0.34255117  0.0946178  -0.12599748  0.03989073  0.01194037  0.15648179\n",
      "  -0.2000215  -0.35689622 -0.03665994  0.22580475  0.11519041  0.37504447\n",
      "  -0.4855888  -0.32720187  0.25055733  0.02761785  0.05622508  0.140466\n",
      "   0.07221731 -0.07039157  0.01549867 -0.13397019 -0.20476606  0.5124332\n",
      "  -0.20790291 -0.05214024  0.18218218  0.18730831 -0.10147913 -0.10880197\n",
      "  -0.0277573   0.11748042 -0.04946781  0.01931577 -0.11396747  0.02900004\n",
      "  -0.03528411  0.37872878 -0.24519546  0.05933668 -0.16084595 -0.10046256\n",
      "   0.10229522  0.16464145  0.10230358  0.08637242 -0.00972914 -0.4519869\n",
      "   0.07706796  0.20707484  0.20560478  0.16611303 -0.00532556  0.12814139\n",
      "  -0.03080037  0.00259987]\n",
      " [-0.00086144 -0.19110487  0.06668795  0.2881564  -0.13071832  0.06547089\n",
      "  -0.25552043 -0.01461081 -0.15167059  0.47444504 -0.1393569  -0.14284879\n",
      "   0.05574106  0.4087304   0.1568392   0.24999341  0.14024514 -0.3323667\n",
      "   0.33315027 -0.47567356  0.22817709  0.24119838 -0.04694829 -0.15140894\n",
      "   0.18076023  0.17754664  0.15933353 -0.06440539  0.36215302 -0.23196153\n",
      "  -0.11985251  0.15597187 -0.19646984  0.00410144  0.15194769  0.26556605\n",
      "  -0.26159465 -0.35341    -0.07359434 -0.07034591  0.04816882 -0.2163291\n",
      "   0.24401979  0.06076012  0.1581922  -0.14221372  0.20331912 -0.04025997\n",
      "  -0.27871305 -0.13356112  0.04048936 -0.09733722  0.0420669   0.14147766\n",
      "   0.16613047  0.09349494  0.04671359 -0.03408171  0.0443463   0.08540923\n",
      "  -0.27006105  0.09889382  0.14077665  0.15951571  0.15823677 -0.11648544\n",
      "  -0.16793855  0.15617569 -0.02764408  0.19771479  0.05753803  0.20711309\n",
      "   0.17650469  0.15972722 -0.02092619  0.16958778 -0.10386704  0.21828629\n",
      "  -0.27319533 -0.30095875  0.05270867  0.11793508  0.23280343  0.3345641\n",
      "  -0.37617895 -0.16717306  0.316595    0.01893448  0.02923961  0.22574562\n",
      "   0.08802108 -0.10824495  0.07207704 -0.08727943 -0.17349786  0.5123133\n",
      "  -0.16373564 -0.05113894 -0.02490294  0.11684614 -0.06335979 -0.12485404\n",
      "  -0.03575514  0.113158   -0.15927173 -0.08859638 -0.08589817  0.03907112\n",
      "  -0.0193548   0.3954946  -0.19261624  0.09938208 -0.13577914 -0.05794418\n",
      "   0.08208769  0.16737781  0.306493   -0.01652405  0.00692214 -0.3332355\n",
      "  -0.05223989  0.22222634  0.31485626  0.07967745 -0.04892949  0.03337179\n",
      "  -0.10501013  0.10351225]] …\n"
     ]
    }
   ],
   "source": [
    "text_enc = MMContextEncoder(text_encoder_name=\"prajjwal1/bert-tiny\")  # any HF model works\n",
    "st_text = SentenceTransformer(modules=[text_enc])\n",
    "\n",
    "example = [raw_ds[\"cell_sentence_1\"][0], raw_ds[\"captions\"][0]]\n",
    "print(\"input →\", example)\n",
    "print(\"embedding →\", st_text.encode(example)[:5], \"…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea798c",
   "metadata": {},
   "source": [
    "`cell_sentence_1` is **treated like ordinary words**, because we never registered numeric embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7a785",
   "metadata": {},
   "source": [
    "If you initialise with `output_token_embeddings=True` you can retrieve the per‑token vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b14276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mengerj/repos/mmcontext/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydev_ipython/matplotlibtools.py:59: MatplotlibDeprecationWarning: The interactive_bk attribute was deprecated in Matplotlib 3.9 and will be removed in 3.11. Use ``matplotlib.backends.backend_registry.list_builtin(matplotlib.backends.BackendFilter.INTERACTIVE)`` instead.\n",
      "  from matplotlib.rcsetup import interactive_bk, non_interactive_bk  # @UnresolvedImport\n",
      "/Users/mengerj/repos/mmcontext/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydev_ipython/matplotlibtools.py:59: MatplotlibDeprecationWarning: The non_interactive_bk attribute was deprecated in Matplotlib 3.9 and will be removed in 3.11. Use ``matplotlib.backends.backend_registry.list_builtin(matplotlib.backends.BackendFilter.NON_INTERACTIVE)`` instead.\n",
      "  from matplotlib.rcsetup import interactive_bk, non_interactive_bk  # @UnresolvedImport\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_enc_tokens = MMContextEncoder(\"prajjwal1/bert-tiny\", output_token_embeddings=True)\n",
    "st_tokens = SentenceTransformer(modules=[text_enc_tokens])\n",
    "\n",
    "res = st_tokens.encode(example, output_value=\"token_embeddings\")\n",
    "print(len(res))  # a list with length of batch size (2)\n",
    "res[0].shape  # the first element is a tensor of shape (n_tokens, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafce232",
   "metadata": {},
   "source": [
    "## 2  Using **pre‑computed** numeric embeddings\n",
    "### 2 a  Feature‑level (gene) tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc7c0c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefixing 'cell_sentence_2': 100%|██████████| 200/200 [00:00<00:00, 99995.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input → sample_idx:g8 g1 g3 g5 g9 g4 g10 g2 g7 g6\n",
      "Pooled Embedding shape: (64,)\n",
      "Token Embedding shape: torch.Size([10, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enc_feat = MMContextEncoder(\n",
    "    \"prajjwal1/bert-tiny\", adapter_hidden_dim=32, adapter_output_dim=64, output_token_embeddings=True\n",
    ")\n",
    "enc_feat.register_initial_embeddings(gene_df, data_origin=\"geneformer\")\n",
    "\n",
    "# prefix the dataset so the processor knows which column is omics\n",
    "pref_ds = enc_feat.prefix_ds(raw_ds, col_id=\"cell_sentence_2\")\n",
    "\n",
    "st_feat = SentenceTransformer(modules=[enc_feat])\n",
    "row = pref_ds[0]\n",
    "print(\"input →\", row[\"cell_sentence_2\"])\n",
    "encoding = st_feat.encode(row[\"cell_sentence_2\"], output_value=\"sentence_embedding\")\n",
    "print(\"Pooled Embedding shape:\", encoding.shape)\n",
    "token_encoding = st_feat.encode(row[\"cell_sentence_2\"], output_value=\"token_embeddings\")\n",
    "print(\"Token Embedding shape:\", token_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0bbd90",
   "metadata": {},
   "source": [
    "### 2 b  Sample‑level tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8078e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefixing 'cell_sentence_1': 100%|██████████| 200/200 [00:00<00:00, 98561.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input → sample_idx:S1\n",
      "Pooled Embedding shape: (64,)\n",
      "Token Embedding shape: torch.Size([1, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enc_samp = MMContextEncoder(\n",
    "    \"prajjwal1/bert-tiny\", adapter_hidden_dim=32, adapter_output_dim=64, output_token_embeddings=True\n",
    ")\n",
    "enc_samp.register_initial_embeddings(sample_df, data_origin=\"pca\")\n",
    "\n",
    "pref_ds2 = enc_samp.prefix_ds(raw_ds, col_id=\"cell_sentence_1\")\n",
    "st_samp = SentenceTransformer(modules=[enc_samp])\n",
    "print(\"input →\", pref_ds2[0][\"cell_sentence_1\"])\n",
    "encoding = st_samp.encode(pref_ds2[0][\"cell_sentence_1\"])\n",
    "print(\"Pooled Embedding shape:\", encoding.shape)\n",
    "token_encoding = st_samp.encode(pref_ds2[0][\"cell_sentence_1\"], output_value=\"token_embeddings\")\n",
    "print(\"Token Embedding shape:\", token_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c5c470",
   "metadata": {},
   "source": [
    "The numeric vectors from `sample_df` are returned **unmodified** by the omics branch and then projected by the adapter.\n",
    "\n",
    "> **Note**  Embedding weights are *not* saved with the model; only the adapter weights are. When you reload the model you must call `register_initial_embeddings` again with a compatible matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a61e8d",
   "metadata": {},
   "source": [
    "## 3  Random‑initialised embeddings (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afe1c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefixing 'cell_sentence_2': 100%|██████████| 200/200 [00:00<00:00, 95325.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.48181853e-02  4.88068089e-02 -7.71359950e-02 -1.94791742e-02\n",
      " -1.65305734e-01  2.07038909e-01 -9.51697305e-02  1.00460630e-02\n",
      " -2.05945764e-02 -8.27556103e-02  3.99987102e-02  2.23212019e-01\n",
      "  4.08632506e-04  8.41276348e-02  9.08150151e-02  1.14676468e-01\n",
      " -3.14155594e-02 -1.24669306e-01  1.00069672e-01  5.08623570e-02\n",
      "  1.08218171e-01  2.77469680e-02 -2.09165335e-01  2.63675805e-02\n",
      "  2.91837787e-05  2.79316418e-02 -1.44141257e-01  1.72094017e-01\n",
      "  2.09506765e-01  1.42657250e-01  2.66109496e-01  1.25485763e-01\n",
      "  7.32748508e-02 -1.65309429e-01  4.83123846e-02 -1.13332473e-01\n",
      "  7.18119442e-02 -2.47363463e-01  2.18929891e-02 -1.42093882e-01\n",
      " -1.46550447e-01 -7.67515227e-02  1.83114987e-02  3.88945173e-03\n",
      "  4.82691042e-02 -3.01351190e-01  5.10653257e-02  3.41373175e-01\n",
      " -1.61226124e-01  3.45270857e-02 -2.84832209e-01 -1.15363762e-01\n",
      "  3.26400856e-03 -1.97847039e-01  1.37544721e-01 -1.67341352e-01\n",
      " -1.19984224e-01  1.34880215e-01 -8.69596004e-02 -9.23934951e-02\n",
      " -1.14667505e-01 -1.10064439e-01  6.69024065e-02 -4.98916060e-02\n",
      " -2.40046367e-01 -3.92423458e-02 -1.04594007e-01  1.47387385e-01\n",
      "  8.47531781e-02  9.57754403e-02  1.31759018e-01 -7.47028366e-02\n",
      "  2.21064631e-02  1.36735782e-01 -4.59195599e-02 -5.59967272e-02\n",
      "  1.16115749e-01  1.11696959e-01 -1.62084699e-02  6.93817213e-02\n",
      " -9.66152921e-03 -4.18473929e-02  1.31464034e-01 -1.24596931e-01\n",
      "  5.09652011e-02  1.01985922e-02 -1.05605699e-01  6.60440465e-03\n",
      " -7.81463757e-02  5.89422546e-02  1.41610473e-01  2.08448231e-01\n",
      "  2.75164932e-01  1.44421056e-01  1.17941864e-01 -9.46426094e-02\n",
      "  7.22825304e-02  6.93004811e-03  1.31048322e-01 -4.77056019e-02\n",
      " -1.30870670e-01  5.92649989e-02  1.98176250e-01  1.35294929e-01\n",
      " -6.33745342e-02  7.66806584e-03 -1.64642796e-01  1.88818231e-01\n",
      " -1.68705150e-01  1.60660490e-01 -1.99507236e-01 -1.82592884e-01\n",
      " -2.79586464e-01  1.23831652e-01  3.51724833e-01 -6.70351535e-02\n",
      "  8.48011300e-02 -1.83561947e-02 -2.16049291e-02 -6.08670451e-02\n",
      "  2.79058963e-01 -1.96959361e-01 -3.92796807e-02  6.51604086e-02\n",
      "  1.28769338e-01  8.68787915e-02 -7.95575455e-02  1.19629830e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enc_rand = MMContextEncoder(\"prajjwal1/bert-tiny\", adapter_hidden_dim=32)\n",
    "enc_rand.random_initial_embeddings(list(gene_df[\"token\"]))\n",
    "pref_ds3 = enc_rand.prefix_ds(raw_ds, col_id=\"cell_sentence_2\")\n",
    "\n",
    "st_rand = SentenceTransformer(modules=[enc_rand])\n",
    "print(st_rand.encode(pref_ds3[0][\"cell_sentence_2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7dfe9",
   "metadata": {},
   "source": [
    "Random vectors let you benchmark how much pre‑computed representations help compared with an uninformed baseline (same dimension, same adapters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f9ce4",
   "metadata": {},
   "source": [
    "## 4  What’s next?\n",
    "* **Training** → use `SentenceTransformerTrainer` with `pref_ds`. Give the model a pair dataset (`label` = 1/0) and a suitable loss, e.g. `CosineSimilarityLoss`.\n",
    "* **Saving / loading** → `st_rand.save(path)`   then   `SentenceTransformer(path)`. Numeric lookup tables are *not* stored—re‑register before inference.\n",
    "* **Hub upload** → after training, `.push_to_hub()` works like for every Sentence‑Transformers model.\n",
    "\n",
    "A dedicated training notebook will cover these steps in detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
